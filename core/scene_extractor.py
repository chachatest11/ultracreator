"""
Scene detection and frame extraction for video analysis
"""
import os
import cv2
from typing import List, Dict, Optional, Callable
from scenedetect import VideoManager, SceneManager
from scenedetect.detectors import ContentDetector


def extract_scenes(
    video_path: str,
    output_dir: str,
    threshold: float = 27.0,
    min_scene_len: float = 0.5,
    progress_callback: Optional[Callable] = None
) -> Dict:
    """
    Extract scenes from video and save first/last frames of each scene

    Args:
        video_path: Path to video file
        output_dir: Directory to save extracted frames
        threshold: Scene detection sensitivity (lower = more sensitive, default 27.0)
        min_scene_len: Minimum scene length in seconds (default 0.5)
        progress_callback: Optional callback function for progress updates

    Returns:
        Dict with scene info and extracted frames
    """

    if not os.path.exists(video_path):
        raise FileNotFoundError(f"Video file not found: {video_path}")

    # Create output directory
    os.makedirs(output_dir, exist_ok=True)

    if progress_callback:
        progress_callback("üìπ ÎπÑÎîîÏò§ Î∂ÑÏÑù Ï§ë...")

    # Initialize video manager and scene manager
    video_manager = VideoManager([video_path])
    scene_manager = SceneManager()

    # Add ContentDetector algorithm (detects cuts based on frame content changes)
    scene_manager.add_detector(
        ContentDetector(threshold=threshold, min_scene_len=int(min_scene_len * video_manager.get_framerate()))
    )

    # Start video manager
    video_manager.start()

    # Detect scenes
    scene_manager.detect_scenes(frame_source=video_manager)

    # Get list of detected scenes
    scene_list = scene_manager.get_scene_list()

    if progress_callback:
        progress_callback(f"‚úÖ {len(scene_list)}Í∞úÏùò Ïû•Î©¥ Í∞êÏßÄÎê®")

    # Release video manager
    video_manager.release()

    if not scene_list:
        return {
            'success': False,
            'message': 'Ïû•Î©¥ÏùÑ Í∞êÏßÄÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§. threshold Í∞íÏùÑ Ï°∞Ï†ïÌï¥Î≥¥ÏÑ∏Ïöî.',
            'scenes': [],
            'frames': []
        }

    # Extract frames using OpenCV
    if progress_callback:
        progress_callback("üñºÔ∏è ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú Ï§ë...")

    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)

    extracted_frames = []

    for idx, (start_time, end_time) in enumerate(scene_list, 1):
        # Calculate frame numbers
        start_frame = int(start_time.get_frames())
        end_frame = int(end_time.get_frames())

        # Extract first frame of scene
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
        ret, frame = cap.read()

        if ret:
            start_filename = f"scene_{idx:03d}_start.jpg"
            start_path = os.path.join(output_dir, start_filename)
            cv2.imwrite(start_path, frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
            extracted_frames.append({
                'scene': idx,
                'type': 'start',
                'path': start_path,
                'frame_num': start_frame,
                'time': start_time.get_seconds()
            })

        # Extract last frame of scene (one frame before next scene starts)
        cap.set(cv2.CAP_PROP_POS_FRAMES, max(start_frame, end_frame - 1))
        ret, frame = cap.read()

        if ret:
            end_filename = f"scene_{idx:03d}_end.jpg"
            end_path = os.path.join(output_dir, end_filename)
            cv2.imwrite(end_path, frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
            extracted_frames.append({
                'scene': idx,
                'type': 'end',
                'path': end_path,
                'frame_num': end_frame - 1,
                'time': end_time.get_seconds()
            })

        if progress_callback and idx % 5 == 0:
            progress_callback(f"üì∏ {idx}/{len(scene_list)} Ïû•Î©¥ Ï≤òÎ¶¨ Ï§ë...")

    cap.release()

    if progress_callback:
        progress_callback(f"‚úÖ Ï¥ù {len(extracted_frames)}Í∞ú ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú ÏôÑÎ£å!")

    # Build scene info
    scenes_info = []
    for idx, (start_time, end_time) in enumerate(scene_list, 1):
        scenes_info.append({
            'scene_num': idx,
            'start_time': start_time.get_seconds(),
            'end_time': end_time.get_seconds(),
            'duration': (end_time - start_time).get_seconds(),
            'start_frame': int(start_time.get_frames()),
            'end_frame': int(end_time.get_frames())
        })

    return {
        'success': True,
        'message': f'{len(scene_list)}Í∞ú Ïû•Î©¥ÏóêÏÑú {len(extracted_frames)}Í∞ú ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú ÏôÑÎ£å',
        'video_path': video_path,
        'output_dir': output_dir,
        'fps': fps,
        'total_scenes': len(scene_list),
        'total_frames': len(extracted_frames),
        'scenes': scenes_info,
        'frames': extracted_frames
    }


def get_scene_summary(result: Dict) -> str:
    """Generate a text summary of scene extraction results"""
    if not result.get('success'):
        return result.get('message', 'Ï∂îÏ∂ú Ïã§Ìå®')

    scenes = result.get('scenes', [])

    summary = f"### üìä Ïû•Î©¥ Î∂ÑÏÑù Í≤∞Í≥º\n\n"
    summary += f"- **Ï¥ù Ïû•Î©¥ Ïàò**: {result['total_scenes']}Í∞ú\n"
    summary += f"- **Ï∂îÏ∂úÎêú ÌîÑÎ†àÏûÑ**: {result['total_frames']}Í∞ú (Í∞Å Ïû•Î©¥Îãπ ÏãúÏûë/ÎÅù)\n"
    summary += f"- **Ï†ÄÏû• ÏúÑÏπò**: `{result['output_dir']}`\n\n"

    summary += "#### Ïû•Î©¥ Î™©Î°ù:\n\n"
    for scene in scenes[:10]:  # Show first 10 scenes
        summary += (
            f"- **Scene {scene['scene_num']}**: "
            f"{scene['start_time']:.1f}s ~ {scene['end_time']:.1f}s "
            f"(Í∏∏Ïù¥: {scene['duration']:.1f}s)\n"
        )

    if len(scenes) > 10:
        summary += f"\n... Î∞è {len(scenes) - 10}Í∞ú Ïû•Î©¥ Îçî\n"

    return summary
