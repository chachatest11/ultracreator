"""
YouTube Trends & Translation Module
"""
import os
from typing import List, Dict, Optional
from datetime import datetime, timedelta
from collections import Counter
import re
from pytrends.request import TrendReq
from deep_translator import GoogleTranslator
import deepl
from dotenv import load_dotenv

# Import YouTube API
from . import youtube_api

load_dotenv()

# YouTube Category IDs (official YouTube category mapping)
YOUTUBE_CATEGORIES = {
    "ê²Œì„": 20,
    "ê³¼í•™/ê¸°ìˆ ": 28,
    "êµìœ¡": 27,
    "ë…¸í•˜ìš°/ìŠ¤íƒ€ì¼": 26,
    "ë‰´ìŠ¤/ì •ì¹˜": 25,
    "ë¹„ì˜ë¦¬/ì‚¬íšŒìš´ë™": 29,
    "ìŠ¤í¬ì¸ ": 17,
    "ì• ì™„ë™ë¬¼/ë™ë¬¼": 15,
    "ì—”í„°í…Œì¸ë¨¼íŠ¸": 24,
    "ì—¬í–‰/ì´ë²¤íŠ¸": 19,
    "ì˜í™”/ì• ë‹ˆë©”ì´ì…˜": 1,
    "ìŒì•…": 10
}

# Language codes for translation (Google Translate codes)
LANGUAGES = {
    "í•œêµ­ì–´": "ko",
    "ì˜ì–´": "en",
    "ì¼ë³¸ì–´": "ja",
    "ì¤‘êµ­ì–´": "zh-CN",  # Chinese Simplified
    "ìŠ¤í˜ì¸ì–´": "es",
    "íŒë””ì–´": "hi",
    "ëŸ¬ì‹œì•„ì–´": "ru"
}

# DeepL language codes (different from Google)
DEEPL_LANGUAGES = {
    "í•œêµ­ì–´": "KO",
    "ì˜ì–´": "EN-US",
    "ì¼ë³¸ì–´": "JA",
    "ì¤‘êµ­ì–´": "ZH",  # DeepL uses ZH for Chinese
    "ìŠ¤í˜ì¸ì–´": "ES",
    "íŒë””ì–´": "HI",
    "ëŸ¬ì‹œì•„ì–´": "RU"
}


class TrendsError(Exception):
    """Trends API error"""
    pass


class TranslationManager:
    """Manages translation using DeepL (if API key available) or Google Translate (free)"""

    def __init__(self):
        self.deepl_api_key = os.getenv("DEEPL_API_KEY", "")
        self.use_deepl = bool(self.deepl_api_key)

        if self.use_deepl:
            try:
                self.deepl_translator = deepl.Translator(self.deepl_api_key)
                print("âœ… DeepL API í™œì„±í™” (ê³ í’ˆì§ˆ ë²ˆì—­)")
            except Exception as e:
                print(f"âš ï¸  DeepL API ì˜¤ë¥˜: {e}")
                print("ğŸ“ Google Translateë¡œ ì „í™˜ (ë¬´ë£Œ)")
                self.use_deepl = False

    def translate(self, text: str, target_lang_name: str, source_lang: str = "ko") -> str:
        """
        Translate text to target language

        Args:
            text: Text to translate
            target_lang_name: Target language name (e.g., 'ì˜ì–´', 'ì¤‘êµ­ì–´')
            source_lang: Source language code (default: 'ko')

        Returns:
            Translated text
        """
        # Get target language code
        target_lang = LANGUAGES.get(target_lang_name, "en")

        # Skip if target is same as source
        if target_lang == source_lang or target_lang_name == "í•œêµ­ì–´":
            return text

        try:
            if self.use_deepl:
                return self._translate_deepl(text, target_lang_name, source_lang)
            else:
                return self._translate_google(text, target_lang, source_lang)
        except Exception as e:
            print(f"âš ï¸  ë²ˆì—­ ì‹¤íŒ¨ ({text[:20]}... â†’ {target_lang_name}): {e}")
            return text

    def _translate_deepl(self, text: str, target_lang_name: str, source_lang: str) -> str:
        """Translate using DeepL API"""
        # Convert to DeepL language codes
        target_deepl = DEEPL_LANGUAGES.get(target_lang_name, "EN-US")
        source_deepl = source_lang.upper()

        result = self.deepl_translator.translate_text(
            text,
            source_lang=source_deepl,
            target_lang=target_deepl
        )
        return result.text

    def _translate_google(self, text: str, target_lang: str, source_lang: str) -> str:
        """Translate using Google Translate (free)"""
        try:
            translator = GoogleTranslator(source=source_lang, target=target_lang)
            result = translator.translate(text)
            return result if result else text
        except Exception as e:
            print(f"âš ï¸  Google ë²ˆì—­ ì˜¤ë¥˜: {e}")
            return text

    def translate_to_all_languages(self, text: str, source_lang: str = "ko") -> Dict[str, str]:
        """
        Translate text to all supported languages

        Returns:
            Dictionary mapping language names to translated text
        """
        translations = {}

        for lang_name in LANGUAGES.keys():
            # í•œêµ­ì–´ëŠ” ì›ë¬¸ ê·¸ëŒ€ë¡œ
            if lang_name == "í•œêµ­ì–´":
                translations[lang_name] = text
            else:
                translations[lang_name] = self.translate(text, lang_name, source_lang)

        return translations


class TrendsExplorer:
    """Explore YouTube trending keywords by category"""

    def __init__(self):
        self.pytrends = TrendReq(hl='ko-KR', tz=540)  # Korea timezone
        self.translator = TranslationManager()

    def _extract_keywords_from_titles(self, titles: List[str], num_keywords: int = 20) -> List[str]:
        """
        Extract trending keyword phrases from video titles
        Uses actual video titles as keywords for maximum relevance

        Args:
            titles: List of video titles
            num_keywords: Number of keywords to extract

        Returns:
            List of extracted keyword phrases (actual video titles or title segments)
        """
        keywords = []
        seen = set()

        # STRATEGY 1: Use short, meaningful titles directly (10-50 characters)
        for title in titles:
            # Clean title
            cleaned = re.sub(r'[ğŸ®ğŸ¯ğŸ”¥ğŸ’¯ğŸ‘â¤ï¸ğŸ˜ŠğŸ˜‚ğŸ¤£ğŸ˜­ğŸ¥°ğŸ˜ğŸ¤”ğŸ’ªğŸ‰ğŸŠâœ¨â­ğŸŒŸğŸ’–ğŸ’•ğŸ’—ğŸ’ğŸ’˜ğŸ’“ğŸ’ğŸ’Ÿâ˜€ï¸ğŸŒ™â›…ğŸŒˆğŸµğŸ¶ğŸ¤ğŸ§ğŸ¬ğŸ“ºğŸ“·ğŸ“¸ğŸ¨ğŸ–¼ï¸]+', '', title)
            cleaned = re.sub(r'[â˜…â˜†â™¡â™¥â†’â†â†‘â†“â– â–¡â—â—‹â—†â—‡â–²â–³â–¼â–½â€»\[\]\(\)]+', '', cleaned)
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()

            # Use titles that are 10-50 characters long (good keyword length)
            if 10 <= len(cleaned) <= 50:
                cleaned_lower = cleaned.lower()
                # Skip if too similar to existing
                if not any(cleaned_lower in s or s in cleaned_lower for s in seen):
                    keywords.append(cleaned)
                    seen.add(cleaned_lower)
                    if len(keywords) >= num_keywords:
                        return keywords

        # STRATEGY 2: Extract first N words from longer titles
        for title in titles:
            cleaned = re.sub(r'[ğŸ®ğŸ¯ğŸ”¥ğŸ’¯ğŸ‘â¤ï¸ğŸ˜ŠğŸ˜‚ğŸ¤£ğŸ˜­ğŸ¥°ğŸ˜ğŸ¤”ğŸ’ªğŸ‰ğŸŠâœ¨â­ğŸŒŸğŸ’–ğŸ’•ğŸ’—ğŸ’ğŸ’˜ğŸ’“ğŸ’ğŸ’Ÿâ˜€ï¸ğŸŒ™â›…ğŸŒˆ\[\]\(\)]+', '', title)
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()

            words = cleaned.split()

            # Try 5-word, 4-word, 3-word phrases from beginning of title
            for n in [5, 4, 3]:
                if len(words) >= n:
                    phrase = ' '.join(words[:n])
                    phrase_lower = phrase.lower()

                    # Check length and uniqueness
                    if 10 <= len(phrase) <= 50:
                        if not any(phrase_lower in s or s in phrase_lower for s in seen):
                            keywords.append(phrase)
                            seen.add(phrase_lower)
                            if len(keywords) >= num_keywords:
                                return keywords
                            break  # Got one phrase from this title, move to next

        # STRATEGY 3: Frequency-based extraction with very low threshold
        phrase_counter = Counter()

        for title in titles:
            cleaned = re.sub(r'[ğŸ®ğŸ¯ğŸ”¥ğŸ’¯ğŸ‘â¤ï¸ğŸ˜ŠğŸ˜‚ğŸ¤£ğŸ˜­ğŸ¥°ğŸ˜ğŸ¤”ğŸ’ªğŸ‰ğŸŠâœ¨â­ğŸŒŸğŸ’–ğŸ’•ğŸ’—ğŸ’ğŸ’˜ğŸ’“ğŸ’ğŸ’Ÿâ˜€ï¸ğŸŒ™â›…ğŸŒˆ\[\]\(\)]+', '', title)
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()
            words = cleaned.split()

            # Extract 3-6 word phrases
            for phrase_len in [6, 5, 4, 3]:
                for i in range(len(words) - phrase_len + 1):
                    phrase = ' '.join(words[i:i + phrase_len])

                    if 10 <= len(phrase) <= 60:
                        # Skip if mostly numbers
                        if sum(c.isdigit() for c in phrase) < len(phrase) * 0.3:
                            phrase_counter[phrase] += 1

        # Add high-frequency phrases
        for phrase, count in phrase_counter.most_common(num_keywords * 3):
            phrase_lower = phrase.lower()
            if not any(phrase_lower in s or s in phrase_lower for s in seen):
                keywords.append(phrase)
                seen.add(phrase_lower)
                if len(keywords) >= num_keywords:
                    return keywords

        # STRATEGY 4: Fallback - just take title segments
        for title in titles:
            cleaned = re.sub(r'[ğŸ®ğŸ¯ğŸ”¥ğŸ’¯ğŸ‘â¤ï¸ğŸ˜ŠğŸ˜‚ğŸ¤£ğŸ˜­ğŸ¥°ğŸ˜ğŸ¤”ğŸ’ªğŸ‰ğŸŠâœ¨â­ğŸŒŸğŸ’–ğŸ’•ğŸ’—ğŸ’ğŸ’˜ğŸ’“ğŸ’ğŸ’Ÿâ˜€ï¸ğŸŒ™â›…ğŸŒˆ\[\]\(\)]+', '', title)
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()

            if 8 <= len(cleaned) <= 60:
                # Split long titles in half
                if len(cleaned) > 30:
                    words = cleaned.split()
                    mid = len(words) // 2
                    phrase = ' '.join(words[:mid])
                    if len(phrase) >= 10:
                        phrase_lower = phrase.lower()
                        if not any(phrase_lower in s or s in phrase_lower for s in seen):
                            keywords.append(phrase)
                            seen.add(phrase_lower)
                else:
                    # Use whole title
                    cleaned_lower = cleaned.lower()
                    if not any(cleaned_lower in s or s in cleaned_lower for s in seen):
                        keywords.append(cleaned)
                        seen.add(cleaned_lower)

                if len(keywords) >= num_keywords:
                    return keywords

        # Calculate average word count
        avg_words = sum(len(k.split()) for k in keywords) / len(keywords) if keywords else 0
        print(f"âœ… ì¶”ì¶œëœ êµ¬ë¬¸: {len(keywords)}ê°œ (í‰ê·  ë‹¨ì–´ ìˆ˜: {avg_words:.1f}ê°œ)")

        return keywords[:num_keywords]

    def get_trending_keywords(
        self,
        category: str,
        num_keywords: int = 20,
        timeframe: str = 'now 7-d'
    ) -> List[str]:
        """
        Get trending keywords for a YouTube category by analyzing popular videos

        Args:
            category: Category name (e.g., 'ê²Œì„', 'ìŠ¤í¬ì¸ ')
            num_keywords: Number of keywords to return
            timeframe: Time range (not used with YouTube API)

        Returns:
            List of trending keywords
        """
        if category not in YOUTUBE_CATEGORIES:
            raise TrendsError(f"Unknown category: {category}")

        category_id = YOUTUBE_CATEGORIES[category]

        try:
            # Get popular videos from YouTube API
            print(f"ğŸ“Š '{category}' ì¹´í…Œê³ ë¦¬ì˜ ì¸ê¸° ì˜ìƒ ì œëª© ë¶„ì„ ì¤‘...")

            # Fetch popular videos for this category
            video_ids = youtube_api.get_popular_videos_by_category(
                category_id,
                max_results=100,  # Analyze top 100 videos
                region_code='KR'  # Korea region
            )

            if not video_ids:
                print(f"âš ï¸  ì¸ê¸° ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ ë°©ë²• ì‚¬ìš©...")
                return self._generate_category_keywords(category, num_keywords)

            # Get video details (titles)
            videos = youtube_api.get_videos_info(video_ids)

            if not videos:
                print(f"âš ï¸  ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ ë°©ë²• ì‚¬ìš©...")
                return self._generate_category_keywords(category, num_keywords)

            # Extract titles
            titles = [video['title'] for video in videos if video.get('title')]

            print(f"âœ… {len(titles)}ê°œ ì˜ìƒ ì œëª© ìˆ˜ì§‘ ì™„ë£Œ")

            # Extract keywords from titles
            keywords = self._extract_keywords_from_titles(titles, num_keywords)

            if len(keywords) < 5:
                print(f"âš ï¸  ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ëŒ€ì²´ ë°©ë²• ì‚¬ìš©...")
                return self._generate_category_keywords(category, num_keywords)

            print(f"âœ… {len(keywords)}ê°œ íŠ¸ë Œë”© í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")
            return keywords

        except Exception as e:
            print(f"âš ï¸  íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            # Fallback: generate keywords
            return self._generate_category_keywords(category, num_keywords)

    def _generate_category_keywords(self, category: str, num_keywords: int) -> List[str]:
        """Generate basic keywords for a category (fallback)"""
        # Basic keyword templates for each category
        templates = {
            "ê²Œì„": [
                "{} í•˜ì´ë¼ì´íŠ¸", "{} ê³µëµ", "{} ë¦¬ë·°", "{} í”Œë ˆì´",
                "{} ì‹ ì‘", "{} ì—…ë°ì´íŠ¸", "{} íŒ", "{} ëª…ì¥ë©´"
            ],
            "ìŠ¤í¬ì¸ ": [
                "{} í•˜ì´ë¼ì´íŠ¸", "{} ê²½ê¸°", "{} ëª…ì¥ë©´", "{} ê³¨",
                "{} ë¦¬ë·°", "{} ë¶„ì„", "{} ì‹¤ì‹œê°„", "{} ì¤‘ê³„"
            ],
            "ìŒì•…": [
                "{} ì‹ ê³¡", "{} ë®¤ì§ë¹„ë””ì˜¤", "{} ë¼ì´ë¸Œ", "{} ì»¤ë²„",
                "{} ë…¸ë˜", "{} ì•¨ë²”", "{} ì½˜ì„œíŠ¸", "{} ë¬´ëŒ€"
            ],
            "ì˜í™”/ì• ë‹ˆë©”ì´ì…˜": [
                "{} ì˜ˆê³ í¸", "{} ë¦¬ë·°", "{} ëª…ì¥ë©´", "{} ë¶„ì„",
                "{} í•´ì„", "{} ìš”ì•½", "{} ê²°ë§", "{} ì‹œë¦¬ì¦ˆ"
            ],
            "êµìœ¡": [
                "{} ê°•ì˜", "{} ì„¤ëª…", "{} ê³µë¶€", "{} ë°°ìš°ê¸°",
                "{} ì´í•´í•˜ê¸°", "{} ì…ë¬¸", "{} ê¸°ì´ˆ", "{} ê³ ê¸‰"
            ],
            "ê³¼í•™/ê¸°ìˆ ": [
                "{} ë¦¬ë·°", "{} ì„¤ëª…", "{} ì‘ë™ì›ë¦¬", "{} ë¹„êµ",
                "{} ë¶„ì„", "{} ì‹ ê¸°ìˆ ", "{} ê°œë°œ", "{} ë°œí‘œ"
            ]
        }

        # Get templates for this category or use generic ones
        category_templates = templates.get(
            category,
            ["{} ì˜ìƒ", "{} ë¦¬ë·°", "{} í•˜ëŠ”ë²•", "{} ì¶”ì²œ"]
        )

        # Generate keywords
        keywords = []
        for template in category_templates[:num_keywords]:
            # Use category name or leave as template
            keyword = template.format(category)
            keywords.append(keyword)

        return keywords

    def explore_category_with_translations(
        self,
        category: str,
        num_keywords: int = 20
    ) -> List[Dict[str, any]]:
        """
        Get trending keywords for a category with multi-language translations

        Returns:
            List of dictionaries with keyword and translations:
            [
                {
                    'keyword': 'ê²Œì„ í•˜ì´ë¼ì´íŠ¸',
                    'translations': {
                        'í•œêµ­ì–´': 'ê²Œì„ í•˜ì´ë¼ì´íŠ¸',
                        'ì˜ì–´': 'game highlights',
                        ...
                    }
                },
                ...
            ]
        """
        # Get trending keywords
        keywords = self.get_trending_keywords(category, num_keywords)

        # Translate each keyword
        results = []
        for keyword in keywords:
            translations = self.translator.translate_to_all_languages(keyword)
            results.append({
                'keyword': keyword,
                'translations': translations
            })

        return results
