"""
YouTube Trends & Translation Module
"""
import os
from typing import List, Dict, Optional
from datetime import datetime, timedelta
from collections import Counter
import re
from pytrends.request import TrendReq
from deep_translator import GoogleTranslator
import deepl
from dotenv import load_dotenv

# Import YouTube API
from . import youtube_api

load_dotenv()

# YouTube Category IDs (official YouTube category mapping)
YOUTUBE_CATEGORIES = {
    "ê²Œì„": 20,
    "ê³¼í•™/ê¸°ìˆ ": 28,
    "êµìœ¡": 27,
    "ë…¸í•˜ìš°/ìŠ¤íƒ€ì¼": 26,
    "ë‰´ìŠ¤/ì •ì¹˜": 25,
    "ë¹„ì˜ë¦¬/ì‚¬íšŒìš´ë™": 29,
    "ìŠ¤í¬ì¸ ": 17,
    "ì• ì™„ë™ë¬¼/ë™ë¬¼": 15,
    "ì—”í„°í…Œì¸ë¨¼íŠ¸": 24,
    "ì—¬í–‰/ì´ë²¤íŠ¸": 19,
    "ì˜í™”/ì• ë‹ˆë©”ì´ì…˜": 1,
    "ìŒì•…": 10
}

# Language codes for translation (Google Translate codes)
LANGUAGES = {
    "í•œêµ­ì–´": "ko",
    "ì˜ì–´": "en",
    "ì¼ë³¸ì–´": "ja",
    "ì¤‘êµ­ì–´": "zh-CN",  # Chinese Simplified
    "ìŠ¤í˜ì¸ì–´": "es",
    "íŒë””ì–´": "hi",
    "ëŸ¬ì‹œì•„ì–´": "ru"
}

# DeepL language codes (different from Google)
DEEPL_LANGUAGES = {
    "í•œêµ­ì–´": "KO",
    "ì˜ì–´": "EN-US",
    "ì¼ë³¸ì–´": "JA",
    "ì¤‘êµ­ì–´": "ZH",  # DeepL uses ZH for Chinese
    "ìŠ¤í˜ì¸ì–´": "ES",
    "íŒë””ì–´": "HI",
    "ëŸ¬ì‹œì•„ì–´": "RU"
}


class TrendsError(Exception):
    """Trends API error"""
    pass


class TranslationManager:
    """Manages translation using DeepL (if API key available) or Google Translate (free)"""

    def __init__(self):
        self.deepl_api_key = os.getenv("DEEPL_API_KEY", "")
        self.use_deepl = bool(self.deepl_api_key)

        if self.use_deepl:
            try:
                self.deepl_translator = deepl.Translator(self.deepl_api_key)
                print("âœ… DeepL API í™œì„±í™” (ê³ í’ˆì§ˆ ë²ˆì—­)")
            except Exception as e:
                print(f"âš ï¸  DeepL API ì˜¤ë¥˜: {e}")
                print("ğŸ“ Google Translateë¡œ ì „í™˜ (ë¬´ë£Œ)")
                self.use_deepl = False

    def translate(self, text: str, target_lang_name: str, source_lang: str = "ko") -> str:
        """
        Translate text to target language

        Args:
            text: Text to translate
            target_lang_name: Target language name (e.g., 'ì˜ì–´', 'ì¤‘êµ­ì–´')
            source_lang: Source language code (default: 'ko')

        Returns:
            Translated text
        """
        # Get target language code
        target_lang = LANGUAGES.get(target_lang_name, "en")

        # Skip if target is same as source
        if target_lang == source_lang or target_lang_name == "í•œêµ­ì–´":
            return text

        try:
            if self.use_deepl:
                return self._translate_deepl(text, target_lang_name, source_lang)
            else:
                return self._translate_google(text, target_lang, source_lang)
        except Exception as e:
            print(f"âš ï¸  ë²ˆì—­ ì‹¤íŒ¨ ({text[:20]}... â†’ {target_lang_name}): {e}")
            return text

    def _translate_deepl(self, text: str, target_lang_name: str, source_lang: str) -> str:
        """Translate using DeepL API"""
        # Convert to DeepL language codes
        target_deepl = DEEPL_LANGUAGES.get(target_lang_name, "EN-US")
        source_deepl = source_lang.upper()

        result = self.deepl_translator.translate_text(
            text,
            source_lang=source_deepl,
            target_lang=target_deepl
        )
        return result.text

    def _translate_google(self, text: str, target_lang: str, source_lang: str) -> str:
        """Translate using Google Translate (free)"""
        try:
            translator = GoogleTranslator(source=source_lang, target=target_lang)
            result = translator.translate(text)
            return result if result else text
        except Exception as e:
            print(f"âš ï¸  Google ë²ˆì—­ ì˜¤ë¥˜: {e}")
            return text

    def translate_to_all_languages(self, text: str, source_lang: str = "ko") -> Dict[str, str]:
        """
        Translate text to all supported languages

        Returns:
            Dictionary mapping language names to translated text
        """
        translations = {}

        for lang_name in LANGUAGES.keys():
            # í•œêµ­ì–´ëŠ” ì›ë¬¸ ê·¸ëŒ€ë¡œ
            if lang_name == "í•œêµ­ì–´":
                translations[lang_name] = text
            else:
                translations[lang_name] = self.translate(text, lang_name, source_lang)

        return translations


class TrendsExplorer:
    """Explore YouTube trending keywords by category"""

    def __init__(self):
        self.pytrends = TrendReq(hl='ko-KR', tz=540)  # Korea timezone
        self.translator = TranslationManager()

    def _extract_keywords_from_titles(self, titles: List[str], num_keywords: int = 20) -> List[str]:
        """
        Extract trending keyword phrases from video titles using n-gram analysis

        Args:
            titles: List of video titles
            num_keywords: Number of keywords to extract

        Returns:
            List of extracted keyword phrases (2-4 words)
        """
        # Minimal stopwords - only remove very common filler words
        stopwords = {
            'ì˜ìƒ', 'ë™ì˜ìƒ', 'ë¹„ë””ì˜¤', 'í´ë¦½', 'ì‡¼ì¸ ', 'ì‡¼íŠ¸', 'shorts',
            'ìœ íŠœë¸Œ', 'youtube', 'ì±„ë„', 'channel',
            'ì…ë‹ˆë‹¤', 'í•©ë‹ˆë‹¤', 'ìˆìŠµë‹ˆë‹¤', 'ì—†ìŠµë‹ˆë‹¤',
            'the', 'a', 'an', 'and', 'or', 'but'
        }

        # Extract phrases of 2-5 words
        phrase_counter = Counter()

        for title in titles:
            # Clean and normalize title - keep most punctuation context
            # Remove brackets, parentheses, quotes but keep words
            cleaned = re.sub(r'[\[\]()ã€Œã€ã€ã€ã€ã€‘\(\)ã€Šã€‹""\'\']+', ' ', title)
            cleaned = re.sub(r'[|â€¢â˜…â˜†â™¡â™¥â†’â†â†‘â†“]+', ' ', cleaned)
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()

            # Split into words but preserve structure
            words = cleaned.split()

            # Create n-grams (2 to 5 words)
            for n in range(2, 6):  # 2, 3, 4, 5 word phrases
                for i in range(len(words) - n + 1):
                    phrase_words = words[i:i+n]

                    # Skip if contains too many stopwords
                    stopword_count = sum(1 for w in phrase_words if w.lower() in stopwords or w in stopwords)
                    if stopword_count > len(phrase_words) // 2:
                        continue

                    # Skip if too many numbers or too short
                    phrase = ' '.join(phrase_words)
                    if len(phrase) < 5:  # At least 5 characters
                        continue

                    # Skip if mostly numbers
                    if sum(c.isdigit() for c in phrase) > len(phrase) // 2:
                        continue

                    phrase_counter[phrase] += 1

        # Get most common phrases
        common_phrases = phrase_counter.most_common(num_keywords * 10)

        # Filter by frequency - at least appear in 2 videos OR in top popular
        min_frequency = max(2, len(titles) // 200)  # Very low threshold (0.5%)

        result_phrases = []
        seen_keywords = set()

        for phrase, count in common_phrases:
            if count < min_frequency:
                continue

            # Check if this phrase is too similar to existing ones
            phrase_lower = phrase.lower()
            is_duplicate = False

            for seen in seen_keywords:
                # Skip if this phrase is a subset or superset of existing phrase
                if phrase_lower in seen or seen in phrase_lower:
                    is_duplicate = True
                    break

            if not is_duplicate:
                result_phrases.append(phrase)
                seen_keywords.add(phrase_lower)

            if len(result_phrases) >= num_keywords:
                break

        # If we don't have enough phrases, relax the filters
        if len(result_phrases) < num_keywords // 2:
            print(f"âš ï¸  ì¶”ì¶œëœ êµ¬ë¬¸ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ ({len(result_phrases)}ê°œ). ë” ë§ì€ êµ¬ë¬¸ ì¶”ì¶œ ì¤‘...")

            # Add more phrases with lower frequency
            for phrase, count in common_phrases:
                if phrase in result_phrases:
                    continue

                phrase_lower = phrase.lower()
                is_duplicate = False
                for seen in seen_keywords:
                    if phrase_lower in seen or seen in phrase_lower:
                        is_duplicate = True
                        break

                if not is_duplicate and count >= 1:  # Just need to appear once
                    result_phrases.append(phrase)
                    seen_keywords.add(phrase_lower)

                if len(result_phrases) >= num_keywords:
                    break

        return result_phrases[:num_keywords]

    def get_trending_keywords(
        self,
        category: str,
        num_keywords: int = 20,
        timeframe: str = 'now 7-d'
    ) -> List[str]:
        """
        Get trending keywords for a YouTube category by analyzing popular videos

        Args:
            category: Category name (e.g., 'ê²Œì„', 'ìŠ¤í¬ì¸ ')
            num_keywords: Number of keywords to return
            timeframe: Time range (not used with YouTube API)

        Returns:
            List of trending keywords
        """
        if category not in YOUTUBE_CATEGORIES:
            raise TrendsError(f"Unknown category: {category}")

        category_id = YOUTUBE_CATEGORIES[category]

        try:
            # Get popular videos from YouTube API
            print(f"ğŸ“Š '{category}' ì¹´í…Œê³ ë¦¬ì˜ ì¸ê¸° ì˜ìƒ ì œëª© ë¶„ì„ ì¤‘...")

            # Fetch popular videos for this category
            video_ids = youtube_api.get_popular_videos_by_category(
                category_id,
                max_results=100,  # Analyze top 100 videos
                region_code='KR'  # Korea region
            )

            if not video_ids:
                print(f"âš ï¸  ì¸ê¸° ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ ë°©ë²• ì‚¬ìš©...")
                return self._generate_category_keywords(category, num_keywords)

            # Get video details (titles)
            videos = youtube_api.get_videos_info(video_ids)

            if not videos:
                print(f"âš ï¸  ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ ë°©ë²• ì‚¬ìš©...")
                return self._generate_category_keywords(category, num_keywords)

            # Extract titles
            titles = [video['title'] for video in videos if video.get('title')]

            print(f"âœ… {len(titles)}ê°œ ì˜ìƒ ì œëª© ìˆ˜ì§‘ ì™„ë£Œ")

            # Extract keywords from titles
            keywords = self._extract_keywords_from_titles(titles, num_keywords)

            if len(keywords) < 5:
                print(f"âš ï¸  ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ëŒ€ì²´ ë°©ë²• ì‚¬ìš©...")
                return self._generate_category_keywords(category, num_keywords)

            print(f"âœ… {len(keywords)}ê°œ íŠ¸ë Œë”© í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")
            return keywords

        except Exception as e:
            print(f"âš ï¸  íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            # Fallback: generate keywords
            return self._generate_category_keywords(category, num_keywords)

    def _generate_category_keywords(self, category: str, num_keywords: int) -> List[str]:
        """Generate basic keywords for a category (fallback)"""
        # Basic keyword templates for each category
        templates = {
            "ê²Œì„": [
                "{} í•˜ì´ë¼ì´íŠ¸", "{} ê³µëµ", "{} ë¦¬ë·°", "{} í”Œë ˆì´",
                "{} ì‹ ì‘", "{} ì—…ë°ì´íŠ¸", "{} íŒ", "{} ëª…ì¥ë©´"
            ],
            "ìŠ¤í¬ì¸ ": [
                "{} í•˜ì´ë¼ì´íŠ¸", "{} ê²½ê¸°", "{} ëª…ì¥ë©´", "{} ê³¨",
                "{} ë¦¬ë·°", "{} ë¶„ì„", "{} ì‹¤ì‹œê°„", "{} ì¤‘ê³„"
            ],
            "ìŒì•…": [
                "{} ì‹ ê³¡", "{} ë®¤ì§ë¹„ë””ì˜¤", "{} ë¼ì´ë¸Œ", "{} ì»¤ë²„",
                "{} ë…¸ë˜", "{} ì•¨ë²”", "{} ì½˜ì„œíŠ¸", "{} ë¬´ëŒ€"
            ],
            "ì˜í™”/ì• ë‹ˆë©”ì´ì…˜": [
                "{} ì˜ˆê³ í¸", "{} ë¦¬ë·°", "{} ëª…ì¥ë©´", "{} ë¶„ì„",
                "{} í•´ì„", "{} ìš”ì•½", "{} ê²°ë§", "{} ì‹œë¦¬ì¦ˆ"
            ],
            "êµìœ¡": [
                "{} ê°•ì˜", "{} ì„¤ëª…", "{} ê³µë¶€", "{} ë°°ìš°ê¸°",
                "{} ì´í•´í•˜ê¸°", "{} ì…ë¬¸", "{} ê¸°ì´ˆ", "{} ê³ ê¸‰"
            ],
            "ê³¼í•™/ê¸°ìˆ ": [
                "{} ë¦¬ë·°", "{} ì„¤ëª…", "{} ì‘ë™ì›ë¦¬", "{} ë¹„êµ",
                "{} ë¶„ì„", "{} ì‹ ê¸°ìˆ ", "{} ê°œë°œ", "{} ë°œí‘œ"
            ]
        }

        # Get templates for this category or use generic ones
        category_templates = templates.get(
            category,
            ["{} ì˜ìƒ", "{} ë¦¬ë·°", "{} í•˜ëŠ”ë²•", "{} ì¶”ì²œ"]
        )

        # Generate keywords
        keywords = []
        for template in category_templates[:num_keywords]:
            # Use category name or leave as template
            keyword = template.format(category)
            keywords.append(keyword)

        return keywords

    def explore_category_with_translations(
        self,
        category: str,
        num_keywords: int = 20
    ) -> List[Dict[str, any]]:
        """
        Get trending keywords for a category with multi-language translations

        Returns:
            List of dictionaries with keyword and translations:
            [
                {
                    'keyword': 'ê²Œì„ í•˜ì´ë¼ì´íŠ¸',
                    'translations': {
                        'í•œêµ­ì–´': 'ê²Œì„ í•˜ì´ë¼ì´íŠ¸',
                        'ì˜ì–´': 'game highlights',
                        ...
                    }
                },
                ...
            ]
        """
        # Get trending keywords
        keywords = self.get_trending_keywords(category, num_keywords)

        # Translate each keyword
        results = []
        for keyword in keywords:
            translations = self.translator.translate_to_all_languages(keyword)
            results.append({
                'keyword': keyword,
                'translations': translations
            })

        return results
