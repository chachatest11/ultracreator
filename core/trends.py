"""
YouTube Trends & Translation Module
"""
import os
from typing import List, Dict, Optional
from datetime import datetime, timedelta
from collections import Counter
import re
from pytrends.request import TrendReq
from deep_translator import GoogleTranslator
import deepl
from dotenv import load_dotenv

# Import YouTube API
from . import youtube_api

load_dotenv()

# YouTube Category IDs (official YouTube category mapping)
YOUTUBE_CATEGORIES = {
    "ê²Œì„": 20,
    "ê³¼í•™/ê¸°ìˆ ": 28,
    "êµìœ¡": 27,
    "ë…¸í•˜ìš°/ìŠ¤íƒ€ì¼": 26,
    "ë‰´ìŠ¤/ì •ì¹˜": 25,
    "ë¹„ì˜ë¦¬/ì‚¬íšŒìš´ë™": 29,
    "ìŠ¤í¬ì¸ ": 17,
    "ì• ì™„ë™ë¬¼/ë™ë¬¼": 15,
    "ì—”í„°í…Œì¸ë¨¼íŠ¸": 24,
    "ì—¬í–‰/ì´ë²¤íŠ¸": 19,
    "ì˜í™”/ì• ë‹ˆë©”ì´ì…˜": 1,
    "ìŒì•…": 10
}

# Language codes for translation (Google Translate codes)
LANGUAGES = {
    "í•œêµ­ì–´": "ko",
    "ì˜ì–´": "en",
    "ì¼ë³¸ì–´": "ja",
    "ì¤‘êµ­ì–´": "zh-CN",  # Chinese Simplified
    "ìŠ¤í˜ì¸ì–´": "es",
    "íŒë””ì–´": "hi",
    "ëŸ¬ì‹œì•„ì–´": "ru"
}

# DeepL language codes (different from Google)
DEEPL_LANGUAGES = {
    "í•œêµ­ì–´": "KO",
    "ì˜ì–´": "EN-US",
    "ì¼ë³¸ì–´": "JA",
    "ì¤‘êµ­ì–´": "ZH",  # DeepL uses ZH for Chinese
    "ìŠ¤í˜ì¸ì–´": "ES",
    "íŒë””ì–´": "HI",
    "ëŸ¬ì‹œì•„ì–´": "RU"
}


class TrendsError(Exception):
    """Trends API error"""
    pass


class TranslationManager:
    """Manages translation using DeepL (if API key available) or Google Translate (free)"""

    def __init__(self):
        self.deepl_api_key = os.getenv("DEEPL_API_KEY", "")
        self.use_deepl = bool(self.deepl_api_key)

        if self.use_deepl:
            try:
                self.deepl_translator = deepl.Translator(self.deepl_api_key)
                print("âœ… DeepL API í™œì„±í™” (ê³ í’ˆì§ˆ ë²ˆì—­)")
            except Exception as e:
                print(f"âš ï¸  DeepL API ì˜¤ë¥˜: {e}")
                print("ğŸ“ Google Translateë¡œ ì „í™˜ (ë¬´ë£Œ)")
                self.use_deepl = False

    def translate(self, text: str, target_lang_name: str, source_lang: str = "ko") -> str:
        """
        Translate text to target language

        Args:
            text: Text to translate
            target_lang_name: Target language name (e.g., 'ì˜ì–´', 'ì¤‘êµ­ì–´')
            source_lang: Source language code (default: 'ko')

        Returns:
            Translated text
        """
        # Get target language code
        target_lang = LANGUAGES.get(target_lang_name, "en")

        # Skip if target is same as source
        if target_lang == source_lang or target_lang_name == "í•œêµ­ì–´":
            return text

        try:
            if self.use_deepl:
                return self._translate_deepl(text, target_lang_name, source_lang)
            else:
                return self._translate_google(text, target_lang, source_lang)
        except Exception as e:
            print(f"âš ï¸  ë²ˆì—­ ì‹¤íŒ¨ ({text[:20]}... â†’ {target_lang_name}): {e}")
            return text

    def _translate_deepl(self, text: str, target_lang_name: str, source_lang: str) -> str:
        """Translate using DeepL API"""
        # Convert to DeepL language codes
        target_deepl = DEEPL_LANGUAGES.get(target_lang_name, "EN-US")
        source_deepl = source_lang.upper()

        result = self.deepl_translator.translate_text(
            text,
            source_lang=source_deepl,
            target_lang=target_deepl
        )
        return result.text

    def _translate_google(self, text: str, target_lang: str, source_lang: str) -> str:
        """Translate using Google Translate (free)"""
        try:
            translator = GoogleTranslator(source=source_lang, target=target_lang)
            result = translator.translate(text)
            return result if result else text
        except Exception as e:
            print(f"âš ï¸  Google ë²ˆì—­ ì˜¤ë¥˜: {e}")
            return text

    def translate_to_all_languages(self, text: str, source_lang: str = "ko") -> Dict[str, str]:
        """
        Translate text to all supported languages

        Returns:
            Dictionary mapping language names to translated text
        """
        translations = {}

        for lang_name in LANGUAGES.keys():
            # í•œêµ­ì–´ëŠ” ì›ë¬¸ ê·¸ëŒ€ë¡œ
            if lang_name == "í•œêµ­ì–´":
                translations[lang_name] = text
            else:
                translations[lang_name] = self.translate(text, lang_name, source_lang)

        return translations


class TrendsExplorer:
    """Explore YouTube trending keywords by category"""

    def __init__(self):
        self.pytrends = TrendReq(hl='ko-KR', tz=540)  # Korea timezone
        self.translator = TranslationManager()

    def _extract_keywords_from_titles(self, titles: List[str], num_keywords: int = 20) -> List[str]:
        """
        Extract trending keyword phrases from video titles

        Args:
            titles: List of video titles
            num_keywords: Number of keywords to extract

        Returns:
            List of extracted keyword phrases
        """
        # Count phrase frequencies
        phrase_counter = Counter()

        # Process each title
        for title in titles:
            # Minimal cleaning - only remove emojis and excessive symbols
            cleaned = re.sub(r'[ğŸ®ğŸ¯ğŸ”¥ğŸ’¯ğŸ‘â¤ï¸ğŸ˜ŠğŸ˜‚ğŸ¤£ğŸ˜­ğŸ¥°ğŸ˜ğŸ¤”ğŸ’ªğŸ‰ğŸŠâœ¨â­ğŸŒŸğŸ’–ğŸ’•ğŸ’—ğŸ’ğŸ’˜ğŸ’“ğŸ’ğŸ’Ÿâ˜€ï¸ğŸŒ™â›…ğŸŒˆğŸµğŸ¶ğŸ¤ğŸ§ğŸ¬ğŸ“ºğŸ“·ğŸ“¸ğŸ¨ğŸ–¼ï¸]+', '', title)
            cleaned = re.sub(r'[â˜…â˜†â™¡â™¥â†’â†â†‘â†“â– â–¡â—â—‹â—†â—‡â–²â–³â–¼â–½â€»]+', '', cleaned)
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()

            if len(cleaned) < 3:
                continue

            # Extract phrases of different lengths
            # For Korean/Asian languages, use character-based approach
            words = cleaned.split()

            # Try extracting 2-6 consecutive words as phrases
            for phrase_len in range(2, 7):
                for i in range(len(words) - phrase_len + 1):
                    phrase = ' '.join(words[i:i + phrase_len])

                    # Basic filtering
                    if len(phrase) < 6:  # Too short
                        continue

                    # Skip if too many numbers
                    digit_count = sum(c.isdigit() for c in phrase)
                    if digit_count > len(phrase) * 0.4:
                        continue

                    # Skip very common filler phrases
                    if any(skip in phrase.lower() for skip in ['shorts', 'ì‡¼ì¸ ', 'youtube', 'ìœ íŠœë¸Œ']):
                        if len(phrase.split()) <= 2:  # Only skip if it's a short phrase
                            continue

                    phrase_counter[phrase] += 1

        # Get most common phrases
        all_phrases = phrase_counter.most_common(num_keywords * 20)

        # Filter and deduplicate
        result = []
        seen_parts = set()

        # First pass: Get phrases with frequency >= 2
        for phrase, count in all_phrases:
            if count < 2:
                continue

            # Check if this phrase is too similar to already selected ones
            phrase_lower = phrase.lower().strip()

            # Skip very short phrases if we have enough results
            if len(result) > num_keywords // 2 and len(phrase) < 10:
                continue

            # Check for duplicates
            is_duplicate = False
            for seen in list(seen_parts):
                # If this phrase completely contains or is contained by an existing one
                if phrase_lower == seen or (phrase_lower in seen and len(phrase_lower) < len(seen) * 0.8):
                    is_duplicate = True
                    break
                # If existing phrase is contained in this one and much shorter
                if seen in phrase_lower and len(seen) < len(phrase_lower) * 0.6:
                    # Replace with longer phrase
                    seen_parts.remove(seen)
                    result = [r for r in result if r.lower() != seen]
                    break

            if not is_duplicate:
                result.append(phrase)
                seen_parts.add(phrase_lower)

            if len(result) >= num_keywords:
                break

        # Second pass: If not enough, add phrases with frequency >= 1
        if len(result) < num_keywords:
            for phrase, count in all_phrases:
                if phrase in result:
                    continue

                phrase_lower = phrase.lower().strip()

                # Check for duplicates
                is_duplicate = False
                for seen in seen_parts:
                    if phrase_lower == seen or phrase_lower in seen or seen in phrase_lower:
                        is_duplicate = True
                        break

                if not is_duplicate and len(phrase) >= 6:
                    result.append(phrase)
                    seen_parts.add(phrase_lower)

                if len(result) >= num_keywords:
                    break

        # If still not enough, extract from title beginnings/endings
        if len(result) < num_keywords // 2:
            print(f"âš ï¸  êµ¬ë¬¸ ì¶”ì¶œ ë¶€ì¡±. ì œëª©ì—ì„œ ì§ì ‘ ì¶”ì¶œ ì¤‘...")
            for title in titles[:50]:  # Sample first 50 titles
                cleaned = re.sub(r'[ğŸ®ğŸ¯ğŸ”¥ğŸ’¯ğŸ‘â¤ï¸ğŸ˜ŠğŸ˜‚ğŸ¤£ğŸ˜­ğŸ¥°ğŸ˜ğŸ¤”ğŸ’ªğŸ‰ğŸŠâœ¨â­ğŸŒŸğŸ’–ğŸ’•ğŸ’—ğŸ’ğŸ’˜ğŸ’“ğŸ’ğŸ’Ÿâ˜€ï¸ğŸŒ™â›…ğŸŒˆ]+', '', title)
                cleaned = re.sub(r'\s+', ' ', cleaned).strip()

                words = cleaned.split()
                if len(words) >= 3:
                    # First 3-4 words
                    phrase = ' '.join(words[:min(4, len(words))])
                    if len(phrase) >= 6 and phrase not in result:
                        result.append(phrase)
                        if len(result) >= num_keywords:
                            break

        return result[:num_keywords]

    def get_trending_keywords(
        self,
        category: str,
        num_keywords: int = 20,
        timeframe: str = 'now 7-d'
    ) -> List[str]:
        """
        Get trending keywords for a YouTube category by analyzing popular videos

        Args:
            category: Category name (e.g., 'ê²Œì„', 'ìŠ¤í¬ì¸ ')
            num_keywords: Number of keywords to return
            timeframe: Time range (not used with YouTube API)

        Returns:
            List of trending keywords
        """
        if category not in YOUTUBE_CATEGORIES:
            raise TrendsError(f"Unknown category: {category}")

        category_id = YOUTUBE_CATEGORIES[category]

        try:
            # Get popular videos from YouTube API
            print(f"ğŸ“Š '{category}' ì¹´í…Œê³ ë¦¬ì˜ ì¸ê¸° ì˜ìƒ ì œëª© ë¶„ì„ ì¤‘...")

            # Fetch popular videos for this category
            video_ids = youtube_api.get_popular_videos_by_category(
                category_id,
                max_results=100,  # Analyze top 100 videos
                region_code='KR'  # Korea region
            )

            if not video_ids:
                print(f"âš ï¸  ì¸ê¸° ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ ë°©ë²• ì‚¬ìš©...")
                return self._generate_category_keywords(category, num_keywords)

            # Get video details (titles)
            videos = youtube_api.get_videos_info(video_ids)

            if not videos:
                print(f"âš ï¸  ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ ë°©ë²• ì‚¬ìš©...")
                return self._generate_category_keywords(category, num_keywords)

            # Extract titles
            titles = [video['title'] for video in videos if video.get('title')]

            print(f"âœ… {len(titles)}ê°œ ì˜ìƒ ì œëª© ìˆ˜ì§‘ ì™„ë£Œ")

            # Extract keywords from titles
            keywords = self._extract_keywords_from_titles(titles, num_keywords)

            if len(keywords) < 5:
                print(f"âš ï¸  ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ëŒ€ì²´ ë°©ë²• ì‚¬ìš©...")
                return self._generate_category_keywords(category, num_keywords)

            print(f"âœ… {len(keywords)}ê°œ íŠ¸ë Œë”© í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")
            return keywords

        except Exception as e:
            print(f"âš ï¸  íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            # Fallback: generate keywords
            return self._generate_category_keywords(category, num_keywords)

    def _generate_category_keywords(self, category: str, num_keywords: int) -> List[str]:
        """Generate basic keywords for a category (fallback)"""
        # Basic keyword templates for each category
        templates = {
            "ê²Œì„": [
                "{} í•˜ì´ë¼ì´íŠ¸", "{} ê³µëµ", "{} ë¦¬ë·°", "{} í”Œë ˆì´",
                "{} ì‹ ì‘", "{} ì—…ë°ì´íŠ¸", "{} íŒ", "{} ëª…ì¥ë©´"
            ],
            "ìŠ¤í¬ì¸ ": [
                "{} í•˜ì´ë¼ì´íŠ¸", "{} ê²½ê¸°", "{} ëª…ì¥ë©´", "{} ê³¨",
                "{} ë¦¬ë·°", "{} ë¶„ì„", "{} ì‹¤ì‹œê°„", "{} ì¤‘ê³„"
            ],
            "ìŒì•…": [
                "{} ì‹ ê³¡", "{} ë®¤ì§ë¹„ë””ì˜¤", "{} ë¼ì´ë¸Œ", "{} ì»¤ë²„",
                "{} ë…¸ë˜", "{} ì•¨ë²”", "{} ì½˜ì„œíŠ¸", "{} ë¬´ëŒ€"
            ],
            "ì˜í™”/ì• ë‹ˆë©”ì´ì…˜": [
                "{} ì˜ˆê³ í¸", "{} ë¦¬ë·°", "{} ëª…ì¥ë©´", "{} ë¶„ì„",
                "{} í•´ì„", "{} ìš”ì•½", "{} ê²°ë§", "{} ì‹œë¦¬ì¦ˆ"
            ],
            "êµìœ¡": [
                "{} ê°•ì˜", "{} ì„¤ëª…", "{} ê³µë¶€", "{} ë°°ìš°ê¸°",
                "{} ì´í•´í•˜ê¸°", "{} ì…ë¬¸", "{} ê¸°ì´ˆ", "{} ê³ ê¸‰"
            ],
            "ê³¼í•™/ê¸°ìˆ ": [
                "{} ë¦¬ë·°", "{} ì„¤ëª…", "{} ì‘ë™ì›ë¦¬", "{} ë¹„êµ",
                "{} ë¶„ì„", "{} ì‹ ê¸°ìˆ ", "{} ê°œë°œ", "{} ë°œí‘œ"
            ]
        }

        # Get templates for this category or use generic ones
        category_templates = templates.get(
            category,
            ["{} ì˜ìƒ", "{} ë¦¬ë·°", "{} í•˜ëŠ”ë²•", "{} ì¶”ì²œ"]
        )

        # Generate keywords
        keywords = []
        for template in category_templates[:num_keywords]:
            # Use category name or leave as template
            keyword = template.format(category)
            keywords.append(keyword)

        return keywords

    def explore_category_with_translations(
        self,
        category: str,
        num_keywords: int = 20
    ) -> List[Dict[str, any]]:
        """
        Get trending keywords for a category with multi-language translations

        Returns:
            List of dictionaries with keyword and translations:
            [
                {
                    'keyword': 'ê²Œì„ í•˜ì´ë¼ì´íŠ¸',
                    'translations': {
                        'í•œêµ­ì–´': 'ê²Œì„ í•˜ì´ë¼ì´íŠ¸',
                        'ì˜ì–´': 'game highlights',
                        ...
                    }
                },
                ...
            ]
        """
        # Get trending keywords
        keywords = self.get_trending_keywords(category, num_keywords)

        # Translate each keyword
        results = []
        for keyword in keywords:
            translations = self.translator.translate_to_all_languages(keyword)
            results.append({
                'keyword': keyword,
                'translations': translations
            })

        return results
